{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rCT0KQzLV4Y"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.data import Options\n",
    "\n",
    "\n",
    "import psutil\n",
    "import subprocess\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configura√ß√£o da GPU no TensorFlow\n",
    "\n",
    "Antes de iniciar o treino do modelo, √© importante garantir que o *TensorFlow* est√° configurado para utilizar a GPU (caso esteja dispon√≠vel). Al√©m disso, ativamos o *memory growth*, que permite ao *TensorFlow* alocar mem√≥ria da GPU conforme necess√°rio, evitando reservar toda a mem√≥ria de uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db341ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar dispositivos f√≠sicos do tipo 'GPU' dispon√≠veis\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Se houver GPUs dispon√≠veis, configurar o memory growth\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Ativar crescimento din√¢mico da mem√≥ria da GPU\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        # Caso a GPU j√° tenha sido inicializada, n√£o √© poss√≠vel alterar a configura√ß√£o\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explora√ß√£o da Estrutura de Diret√≥rios\n",
    "\n",
    "Antes de carregar os dados, √© importante garantir que o caminho para os ficheiros est√° correto e que a estrutura de diret√≥rios est√° bem organizada. O seguinte bloco de c√≥digo permite:\n",
    "\n",
    "- Definir o caminho base (`root_path`) para o projeto.\n",
    "- Listar os diret√≥rios existentes na raiz.\n",
    "- Verificar se o diret√≥rio do dataset (`garbage-noaug-70-15-15`) existe e visualizar o seu conte√∫do.\n",
    "- Explorar de forma recursiva a estrutura de diret√≥rios, mostrando ficheiros e pastas com indenta√ß√£o hier√°rquica.\n",
    "\n",
    "Este passo √© essencial para:\n",
    "- Validar que os dados est√£o organizados corretamente.\n",
    "- Evitar erros de caminho ao carregar imagens para treino, valida√ß√£o e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gnERLOeGV_O",
    "outputId": "e457719c-f736-40cf-c5cb-100833cb2b95"
   },
   "outputs": [],
   "source": [
    "# Caminho local para a pasta raiz do projeto\n",
    "root_path = \"./\"  \n",
    "\n",
    "# Listar diret√≥rios no caminho raiz\n",
    "print(\"üìÅ Diret√≥rios no caminho raiz:\")\n",
    "print(os.listdir(root_path))\n",
    "\n",
    "# Verificar conte√∫do de um caminho espec√≠fico\n",
    "specific_path = os.path.join(root_path, \"garbage-noaug-70-15-15\")\n",
    "if os.path.exists(specific_path):\n",
    "    print(f\"\\nüìÅ Conte√∫do de {specific_path}:\")\n",
    "    print(os.listdir(specific_path))\n",
    "else:\n",
    "    print(f\"\\n‚ùå Caminho {specific_path} n√£o existe\")\n",
    "\n",
    "# Fun√ß√£o para listar diret√≥rios com profundidade\n",
    "def list_dirs(path, indent=0):\n",
    "    for item in os.listdir(path):\n",
    "        full_path = os.path.join(path, item)\n",
    "        if os.path.isdir(full_path):\n",
    "            print(\" \" * indent + \"üìÅ \" + item)\n",
    "            if indent < 4:\n",
    "                list_dirs(full_path, indent + 2)\n",
    "        else:\n",
    "            print(\" \" * indent + \"üìÑ \" + item)\n",
    "\n",
    "# Explorar estrutura de diret√≥rios\n",
    "print(\"\\nüìÇ Estrutura de diret√≥rios:\")\n",
    "list_dirs(root_path, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dete√ß√£o e Configura√ß√£o Otimizada de GPU (Apple Silicon / Metal)\n",
    "\n",
    "Este bloco de c√≥digo trata da dete√ß√£o e configura√ß√£o de dispositivos de acelera√ß√£o como GPUs ou MPS (Metal Performance Shaders), especialmente √∫til em Macs com Apple Silicon.\n",
    "\n",
    "#### Funcionalidades:\n",
    "- Procura dispositivos GPU dispon√≠veis (TensorFlow ‚â• 2.5 reconhece Metal como `GPU`).\n",
    "- Se n√£o encontrar GPU, tenta encontrar dispositivos `MPS` diretamente.\n",
    "- Ativa `memory growth` para evitar aloca√ß√£o antecipada excessiva de mem√≥ria.\n",
    "- Verifica e imprime os dispositivos vis√≠veis.\n",
    "- Executa uma multiplica√ß√£o de matrizes simples para testar a acelera√ß√£o via GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Metal GPU detection for Apple Silicon\n",
    "try:\n",
    "    # First try looking for GPU devices (newer TF versions label Metal as GPU)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if len(gpus) > 0:\n",
    "        print(f\"Found {len(gpus)} GPU device(s)\")\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU acceleration enabled (Metal)\")\n",
    "    # If no GPU found, try looking specifically for MPS devices\n",
    "    elif hasattr(tf.config, 'list_physical_devices') and len(tf.config.list_physical_devices('MPS')) > 0:\n",
    "        mps_devices = tf.config.list_physical_devices('MPS')\n",
    "        tf.config.experimental.set_visible_devices(mps_devices[0], 'MPS')\n",
    "        print(\"MPS (Metal) device enabled\")\n",
    "    else:\n",
    "        print(\"No GPU or MPS device found, using CPU\")\n",
    "        \n",
    "    # Verify what device is being used\n",
    "    print(\"\\nDevice being used:\", tf.config.get_visible_devices())\n",
    "    \n",
    "    # Test with a simple operation to confirm GPU usage\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"Matrix multiplication result:\", c)\n",
    "        print(\"GPU test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up GPU: {e}\")\n",
    "    print(\"Falling back to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Precision Training (FP16)\n",
    "\n",
    "Este bloco de c√≥digo ativa o **mixed precision training**, que usa `float16` (FP16) em vez de `float32` (FP32), sempre que poss√≠vel.\n",
    "\n",
    "#### Benef√≠cios:\n",
    "- Maior desempenho em GPUs modernas, como as da arquitetura Volta, Turing, Ampere ou Apple Silicon com suporte a Metal.\n",
    "- Menor uso de mem√≥ria, permitindo treinar modelos maiores ou\n",
    "\n",
    "#### Como funciona:\n",
    "- Opera√ß√µes matem√°ticas intensas usam `float16`\n",
    "- A perda (`loss`) e os pesos principais mant√™m-se em `float32` para estabilidade num√©rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision (faster on GPU)\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')  # Use FP16 instead of FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Carregamento e Prepara√ß√£o dos Dados\n",
    "\n",
    "Este bloco de c√≥digo realiza a prepara√ß√£o do dataset antes do treino do modelo, incluindo carregamento das imagens, redimensionamento, batching e otimiza√ß√µes de desempenho.\n",
    "\n",
    "#### Defini√ß√£o de Caminhos\n",
    "\n",
    "```python\n",
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "```\n",
    "\n",
    "Define os caminhos para os diret√≥rios contendo os dados de treino, valida√ß√£o e teste. Espera-se que o `specific_path` aponte para a pasta raiz onde os dados est√£o organizados em subpastas por classe.\n",
    "\n",
    "#### Configura√ß√µes de Imagem\n",
    "\n",
    "```python\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "```\n",
    "\n",
    "- `IMG_SIZE`: Redimensiona todas as imagens para 128x128. Apesar das imagens originais serem 640x640, reduzir o tamanho melhora a velocidade de treino e reduz o uso de mem√≥ria.\n",
    "- `BATCH_SIZE`: Define o n√∫mero de imagens por batch. Um valor de 64 √© eficiente para GPUs com mem√≥ria moderada.\n",
    "\n",
    "#### Carregamento do Dataset\n",
    "\n",
    "```python\n",
    "image_dataset_from_directory(...)\n",
    "```\n",
    "\n",
    "Carrega as imagens a partir dos diret√≥rios com as seguintes op√ß√µes:\n",
    "\n",
    "- Redimensionamento para o tamanho especificado.\n",
    "- Organiza√ß√£o autom√°tica dos dados por classes (com base nas subpastas).\n",
    "- Convers√£o em batches para serem usados no treino.\n",
    "\n",
    "S√£o criados tr√™s datasets:\n",
    "\n",
    "- `train_dataset`: para treino do modelo.\n",
    "- `validation_dataset`: para avalia√ß√£o durante o treino.\n",
    "- `test_dataset`: para avalia√ß√£o final.\n",
    "\n",
    "#### Prefetching para Acelera√ß√£o\n",
    "\n",
    "```python\n",
    ".prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "```\n",
    "\n",
    "Usa `prefetch` para carregar os dados no background enquanto o modelo treina, o que reduz o tempo de espera entre batches e melhora o desempenho.\n",
    "\n",
    "\n",
    "#### Limitar Dados para Testes R√°pidos\n",
    "\n",
    "```python\n",
    "train_dataset_pref = train_dataset_pref.take(100)\n",
    "```\n",
    "\n",
    "Limita o n√∫mero de batches usados no treino. √ötil durante testes r√°pidos para evitar longos tempos de treino enquanto se afina a arquitetura ou outros detalhes.\n",
    "\n",
    "#### Otimiza√ß√µes Adicionais\n",
    "\n",
    "```python\n",
    "options = Options()\n",
    "options.experimental_optimization.parallel_batch = False\n",
    "```\n",
    "\n",
    "Desativa o batching paralelo autom√°tico (por vezes usado por TensorFlow), o que pode ser necess√°rio em ambientes com recursos limitados ou para evitar conflitos de performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM_Q87BIO7Bo",
    "outputId": "8bf53a53-57b1-45bd-d7ac-7e0b0aa95b05"
   },
   "outputs": [],
   "source": [
    "# Defini√ß√£o das diretorias de treino, valida√ß√£o e teste\n",
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "\n",
    "# Definir o tamanho das imagens e o tamanho do batch\n",
    "# (Imagens originais t√™m 640px, mas 128px acelera o treino)\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# Carregar o dataset de treino a partir da diret√≥ria\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE), # Redimensionar imagens\n",
    "    batch_size=BATCH_SIZE            # Dividir em batches\n",
    ")\n",
    "\n",
    "# Carregar o dataset de valida√ß√£o\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Carregar o dataset de teste\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Aplicar prefetching para otimizar o carregamento dos dados durante o treino\n",
    "train_dataset_pref = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset_pref = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset_pref = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# (Opcional) limitar o n√∫mero de batches de treino para testes mais r√°pidos\n",
    "train_dataset_pref = train_dataset_pref.take(100)\n",
    "\n",
    "# Ajustar op√ß√µes do dataset para evitar paralelismo autom√°tico no batching\n",
    "options = Options()\n",
    "options.experimental_optimization.parallel_batch = False\n",
    "train_dataset_pref = train_dataset_pref.with_options(options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica√ß√£o do Balanceamento das Classes\n",
    "\n",
    "Antes de treinar o modelo, √© importante compreender a distribui√ß√£o de amostras entre as diferentes classes. Um dataset desbalanceado pode afetar negativamente a performance do modelo, especialmente em classes minorit√°rias.\n",
    "\n",
    "O c√≥digo abaixo calcula o n√∫mero de exemplos por classe no dataset de treino (`train_dataset`), construindo um dicion√°rio com contagens e depois convertendo essa informa√ß√£o num DataFrame para visualiza√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYyaeQfoQP3B",
    "outputId": "cca51f1e-b6b2-4db3-8ccd-dabaf62b3556"
   },
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "class_counts = {}\n",
    "# Itera sobre os batches do dataset de treino\n",
    "for _, labels in train_dataset:\n",
    "    for label in labels.numpy():\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Cria um DataFrame com a contagem por classe\n",
    "df = pd.DataFrame({'class': train_dataset.class_names, 'count': [class_counts.get(i, 0) for i in range(len(train_dataset.class_names))]})\n",
    "\n",
    "# Mostra o DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defini√ß√£o da Arquitetura CNN com Normaliza√ß√£o por Batch\n",
    "\n",
    "Nesta sec√ß√£o, foi constru√≠da manualmente uma rede neuronal convolucional (CNN) simples, composta por tr√™s blocos convolucionais seguidos de camadas densas. O objetivo desta arquitetura √© realizar a classifica√ß√£o das imagens em m√∫ltiplas categorias com base nos dados de treino previamente carregados.\n",
    "\n",
    "O pr√©-processamento inicial das imagens consistiu na normaliza√ß√£o dos valores de pixel para o intervalo `[0, 1]`, o que facilita a converg√™ncia do modelo durante o treino.\n",
    "\n",
    "Cada bloco convolucional √© composto por:\n",
    "\n",
    "- Uma camada `Conv2D` com `padding='same'` para preservar a dimens√£o espacial,\n",
    "- Uma camada `BatchNormalization` que normaliza as ativa√ß√µes antes da fun√ß√£o de ativa√ß√£o,\n",
    "- Uma fun√ß√£o de ativa√ß√£o `ReLU`, e\n",
    "- Uma camada `MaxPooling2D` que reduz a dimens√£o espacial e extrai as caracter√≠sticas mais importantes.\n",
    "\n",
    "Ap√≥s os tr√™s blocos convolucionais, a sa√≠da √© achatada e passada por uma camada densa (`Dense`) com 256 unidades, seguida novamente de `BatchNormalization` e `ReLU`, al√©m de uma camada `Dropout` para reduzir o risco de overfitting.\n",
    "\n",
    "Por fim, uma camada `Dense` com fun√ß√£o de ativa√ß√£o `softmax` √© utilizada para produzir as probabilidades para cada uma das classes, permitindo a classifica√ß√£o final da imagem.\n",
    "\n",
    "O modelo foi compilado com o otimizador Adam, uma taxa de aprendizagem de `1e-3`, e a fun√ß√£o de perda `sparse_categorical_crossentropy`, adequada para problemas de classifica√ß√£o multiclasse com r√≥tulos inteiros.\n",
    "\n",
    "O modelo foi resumido com `model.summary()` para visualizar a arquitetura e o n√∫mero total de par√¢metros trein√°veis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CqMUaOEQawK"
   },
   "outputs": [],
   "source": [
    "# Definir a arquitetura da CNN com BatchNormalization antes da ativa√ß√£o\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# Primeira camada convolucional\n",
    "x = layers.Conv2D(32, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# Segunda camada convolucional\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# Terceira camada convolucional\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# Camadas densas\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Camada de sa√≠da\n",
    "outputs = layers.Dense(len(train_dataset.class_names), activation='softmax')(x)\n",
    "\n",
    "# Criar o modelo\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Otimizador\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlo de Tempo no Treino com Callback Personalizado\n",
    "\n",
    "Durante o treino de modelos de deep learning, √© comum que sess√µes de treino longas causem sobreaquecimento de dispositivos locais, especialmente em ambientes com recursos limitados, como computadores port√°teis ou dispositivos integrados. Para mitigar este problema, foi implementado um **callback personalizado** que permite interromper o treino automaticamente ap√≥s um determinado tempo m√°ximo.\n",
    "\n",
    "#### Descri√ß√£o da L√≥gica\n",
    "\n",
    "Foi criada uma classe chamada `TimeoutCallback`, que herda de `tf.keras.callbacks.Callback`. Esta classe √© inicializada com um par√¢metro `max_time_mins`, que define o tempo m√°ximo de treino em minutos. O tempo de in√≠cio √© registado no momento da cria√ß√£o do callback.\n",
    "\n",
    "A l√≥gica de controlo √© aplicada ao final de cada √©poca (`on_epoch_end`). Nesta fase, √© calculado o tempo decorrido desde o in√≠cio do treino. Se o tempo exceder o limite especificado, o treino √© interrompido automaticamente com a instru√ß√£o `self.model.stop_training = True`.\n",
    "\n",
    "Esta abordagem √© particularmente √∫til em:\n",
    "- Situa√ß√µes em que o treino √© feito localmente e se pretende evitar uso excessivo do processador/GPU.\n",
    "- Processos experimentais em que se deseja limitar o tempo de execu√ß√£o.\n",
    "- Ambientes partilhados com restri√ß√µes de tempo ou energia.\n",
    "\n",
    "#### Par√¢metros Utilizados\n",
    "\n",
    "- `max_time_mins=20`: define um tempo m√°ximo de treino de 20 minutos.\n",
    "- O tempo √© convertido para segundos (`max_time_sec`) para facilitar a compara√ß√£o com o tempo decorrido.\n",
    "- Ao atingir esse tempo, o treino termina automaticamente com uma mensagem de aviso no terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout callback to stop training after a certain time limit\n",
    "class TimeoutCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, max_time_mins=2):\n",
    "        super().__init__()\n",
    "        self.max_time_sec = max_time_mins * 60\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        if elapsed > self.max_time_sec:\n",
    "            print(f\"\\nReached time limit ({self.max_time_sec/3600:.1f}h). Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Maximum 20 minutes of training to prevent overheating\n",
    "timeout_cb = TimeoutCallback(max_time_mins=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Estrat√©gias de Regulariza√ß√£o e Otimiza√ß√£o durante o Treino\n",
    "\n",
    "Durante o processo de treino do modelo, foram aplicadas diversas estrat√©gias para melhorar a performance e evitar *overfitting*:\n",
    "\n",
    "### EarlyStopping\n",
    "\n",
    "Foi utilizado o callback `EarlyStopping` com os seguintes par√¢metros:\n",
    "\n",
    "- **monitor**: `val_accuracy` ‚Äì o treino √© monitorizado com base na precis√£o da valida√ß√£o.\n",
    "- **patience**: `5` ‚Äì se a m√©trica monitorizada n√£o melhorar durante 5 √©pocas consecutivas, o treino √© interrompido.\n",
    "- **restore_best_weights**: `True` ‚Äì garante que os pesos do modelo com melhor desempenho na valida√ß√£o sejam restaurados ap√≥s o t√©rmino do treino.\n",
    "\n",
    "Esta t√©cnica √© √∫til para evitar *overfitting* e desperd√≠cio de recursos computacionais em √©pocas desnecess√°rias.\n",
    "\n",
    "### ModelCheckpoint\n",
    "\n",
    "Foi utilizado o callback `ModelCheckpoint` para guardar automaticamente o modelo com melhor desempenho de valida√ß√£o:\n",
    "\n",
    "- **filepath**: `\"models/model_checkpoint.keras\"` ‚Äì local onde o modelo √© guardado.\n",
    "- **save_best_only**: `True` ‚Äì guarda apenas o modelo com melhor desempenho.\n",
    "- **monitor**: `val_accuracy` ‚Äì a m√©trica utilizada para definir o melhor modelo.\n",
    "\n",
    "Este m√©todo assegura que, mesmo que o treino continue ap√≥s o ponto √≥timo, o melhor modelo est√° sempre dispon√≠vel.\n",
    "\n",
    "### ReduceLROnPlateau\n",
    "\n",
    "Para ajustar dinamicamente a taxa de aprendizagem, foi aplicado o callback `ReduceLROnPlateau`:\n",
    "\n",
    "- **monitor**: `val_loss` ‚Äì reduz a `learning rate` com base na perda de valida√ß√£o.\n",
    "- **factor**: `0.2` ‚Äì a `learning rate` √© multiplicada por este fator.\n",
    "- **patience**: `3` ‚Äì se n√£o houver melhoria na perda durante 3 √©pocas, a taxa de aprendizagem √© reduzida.\n",
    "- **min_lr**: `1e-6` ‚Äì taxa de aprendizagem m√≠nima permitida.\n",
    "\n",
    "Esta t√©cnica melhora a converg√™ncia do modelo, especialmente em fases em que a otimiza√ß√£o desacelera.\n",
    "\n",
    "### C√°lculo dos Pesos das Classes\n",
    "\n",
    "Para mitigar o desbalanceamento entre classes no dataset, foram calculados pesos inversamente proporcionais √† frequ√™ncia de cada classe. O objetivo √© for√ßar o modelo a prestar mais aten√ß√£o √†s classes menos representadas, melhorando a generaliza√ß√£o e o equil√≠brio na predi√ß√£o.\n",
    "\n",
    "O dicion√°rio `class_weight` associa cada classe ao seu respetivo peso, baseado na f√≥rmula:\n",
    "\n",
    "```\n",
    "peso_da_classe_i = total_de_amostras / n√∫mero_de_amostras_na_classe_i\n",
    "```\n",
    "\n",
    "Este dicion√°rio pode ser passado diretamente ao m√©todo `model.fit()` durante o treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WURl_OhwQg_E",
    "outputId": "3484b4a3-12a5-439a-cf55-da9bd59f90ea"
   },
   "outputs": [],
   "source": [
    "# Callback para early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Callback para salvar o modelo com melhor desempenho\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"models/model_checkpoint.keras\", \n",
    "    save_best_only=True,\n",
    "    monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "# Add more callbacks for better training\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Calculate class weights\n",
    "total = sum(class_counts.values())\n",
    "class_weight = {i: total/count for i, count in class_counts.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoriza√ß√£o de Recursos durante o Treino\n",
    "\n",
    "Com o objetivo de acompanhar o impacto computacional durante o processo de treino, foi implementada uma callback personalizada chamada `ResourceMonitorCallback`. Esta classe estende a API de `tf.keras.callbacks.Callback` e permite monitorizar periodicamente o uso de CPU, mem√≥ria e temperatura do sistema, especialmente √∫til para ambientes de treino locais, como port√°teis ou workstations.\n",
    "\n",
    "### Funcionamento\n",
    "\n",
    "A callback √© ativada no final de cada √©poca (`on_epoch_end`) e realiza as seguintes tarefas:\n",
    "\n",
    "- **Uso de CPU**: Recolhe a percentagem de utiliza√ß√£o da CPU utilizando a biblioteca `psutil`.\n",
    "- **Uso de Mem√≥ria**: Calcula a percentagem e a quantidade de mem√≥ria RAM em uso (em GB).\n",
    "- **Temperatura (macOS)**: Se o sistema for um Mac, tenta obter informa√ß√µes t√©rmicas simplificadas atrav√©s do comando `pmset` (sem necessidade de permiss√µes elevadas).\n",
    "- **Estado da GPU**: Mostra se h√° atividade reconhecida na GPU, sendo uma estimativa simplificada para sistemas macOS.\n",
    "\n",
    "### Par√¢metro `check_interval`\n",
    "\n",
    "O construtor da classe permite configurar o par√¢metro `check_interval`, que define a frequ√™ncia (em n√∫mero de √©pocas) com que a monitoriza√ß√£o √© realizada. Neste projeto, foi definido para verificar **a cada √©poca** (`check_interval=1`), garantindo um controlo cont√≠nuo e detalhado ao longo do treino.\n",
    "\n",
    "### Benef√≠cios\n",
    "\n",
    "Esta abordagem permite:\n",
    "- Detetar sobrecargas de CPU ou mem√≥ria que possam afetar a estabilidade do treino;\n",
    "- Avaliar a efici√™ncia dos recursos utilizados;\n",
    "- Observar o comportamento t√©rmico em dispositivos m√≥veis (√∫til em laptops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceMonitorCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, check_interval=1):\n",
    "        super().__init__()\n",
    "        self.check_interval = check_interval\n",
    "        self.epoch_count = 0\n",
    "        self.is_mac = platform.system() == 'Darwin'\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_count += 1\n",
    "        if self.epoch_count % self.check_interval == 0:\n",
    "            # Get basic info\n",
    "            cpu_percent = psutil.cpu_percent(interval=0.5)\n",
    "            memory = psutil.virtual_memory()\n",
    "            mem_used = f\"{memory.percent}% ({memory.used / 1024**3:.1f}GB)\"\n",
    "            \n",
    "            # Temperature check - simplified\n",
    "            temp = \"N/A\"\n",
    "            if self.is_mac:\n",
    "                try:\n",
    "                    # Try thermal level from pmset (no sudo needed)\n",
    "                    result = subprocess.run(['pmset', '-g', 'therm'], capture_output=True, text=True)\n",
    "                    if \"CPU_Thermal_level\" in result.stdout:\n",
    "                        temp = result.stdout.strip()\n",
    "                except: pass\n",
    "            \n",
    "            # Simplified output\n",
    "            print(f\"\\n[Epoch {epoch}] CPU: {cpu_percent}% | Memory: {mem_used}\")\n",
    "            print(f\"Thermal: {temp}\")\n",
    "            print(f\"GPU: {'Active' if self.is_mac else 'Unknown'}\")\n",
    "\n",
    "# Create monitor that checks every epoch\n",
    "resource_monitor = ResourceMonitorCallback(check_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Treino do Modelo com Callbacks e Salvamento\n",
    "\n",
    "Nesta etapa, o modelo √© treinado utilizando diversas estrat√©gias de regulariza√ß√£o e monitoriza√ß√£o para garantir um desempenho robusto e prevenir overfitting ou consumo excessivo de recursos.\n",
    "\n",
    "#### Treinamento com `model.fit()`\n",
    "\n",
    "O m√©todo `model.fit()` √© invocado com os seguintes par√¢metros:\n",
    "\n",
    "- `train_dataset_pref`: conjunto de dados de treino, com prefetching e otimiza√ß√µes aplicadas.\n",
    "- `validation_dataset_pref`: conjunto de valida√ß√£o para monitorizar o desempenho do modelo.\n",
    "- `epochs=20`: o treino ser√° realizado por um m√°ximo de 20 √©pocas.\n",
    "- `class_weight=class_weight`: pesos s√£o aplicados √†s classes para corrigir desequil√≠brios no n√∫mero de exemplos por classe.\n",
    "- `callbacks`: lista de fun√ß√µes auxiliares que atuam durante o treino, incluindo:\n",
    "  - `early_stopping`: para interromper o treino quando a m√©trica de valida√ß√£o parar de melhorar;\n",
    "  - `reduce_lr`: para diminuir a taxa de aprendizagem se o desempenho estagnar;\n",
    "  - `checkpoint_cb`: para salvar o modelo sempre que atinge uma nova melhor performance;\n",
    "  - `timeout_cb`: para limitar a dura√ß√£o do treino;\n",
    "  - `resource_monitor`: para monitorar a mem√≥ria e uso de GPU durante o treino.\n",
    "\n",
    "#### Salvamento do Modelo\n",
    "\n",
    "Ap√≥s o treino:\n",
    "\n",
    "- O modelo completo (arquitetura, pesos e estado do otimizador) √© salvo no formato `.keras`, facilitando o reuso ou exporta√ß√£o.\n",
    "- Os pesos do modelo s√£o tamb√©m salvos separadamente em formato `.h5`, o que pode ser √∫til para carregar apenas os pesos em outra arquitetura id√™ntica.\n",
    "\n",
    "Estas pr√°ticas asseguram que o melhor modelo obtido durante o treino √© guardado e reutiliz√°vel, tanto em produ√ß√£o como para avalia√ß√£o futura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with early stopping and resource monitoring\n",
    "history = model.fit(\n",
    "    train_dataset_pref,\n",
    "    validation_data=validation_dataset_pref,\n",
    "    epochs=20,\n",
    "    class_weight=class_weight, \n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint_cb, timeout_cb, resource_monitor]\n",
    ")\n",
    "\n",
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "model.save(\"models/garbage_classifier_model_early_stopping.keras\")  \n",
    "model.save_weights(\"models/garbage_classifier_early_stopping.weights.h5\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o da Evolu√ß√£o do Treino\n",
    "\n",
    "Para uma an√°lise mais clara e interpret√°vel do comportamento do modelo durante o treino, foi gerado um gr√°fico de dupla visualiza√ß√£o com os dados recolhidos a partir do hist√≥rico (`history`) fornecido pelo m√©todo `model.fit()`.\n",
    "\n",
    "### Conte√∫do Visualizado\n",
    "\n",
    "O gr√°fico apresenta duas m√©tricas fundamentais, tanto para os dados de treino como de valida√ß√£o:\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - Mostra a propor√ß√£o de previs√µes corretas realizadas pelo modelo.\n",
    "   - Indicador direto da efic√°cia do modelo em classificar corretamente os exemplos.\n",
    "\n",
    "2. **Loss**:\n",
    "   - Representa o valor da fun√ß√£o de perda, indicando o qu√£o bem o modelo est√° a ajustar-se aos dados.\n",
    "   - Quanto menor o valor, melhor o desempenho do modelo (em teoria).\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Esta visualiza√ß√£o tem como objetivo:\n",
    "\n",
    "- Identificar sinais de **overfitting** (quando a accuracy de treino continua a aumentar mas a de valida√ß√£o estagna ou diminui);\n",
    "- Confirmar a **converg√™ncia** do modelo (quando tanto a loss como a accuracy estabilizam);\n",
    "- Ajudar a determinar o n√∫mero ideal de √©pocas (epochs) para treino.\n",
    "\n",
    "### Interpreta√ß√£o\n",
    "\n",
    "- Um **comportamento ideal** √© caracterizado por curvas de treino e valida√ß√£o que convergem e permanecem relativamente pr√≥ximas.\n",
    "- Se a `validation loss` come√ßar a aumentar enquanto a `training loss` diminui, pode indicar **overfitting**.\n",
    "- Um bom alinhamento entre `training accuracy` e `validation accuracy` sugere que o modelo est√° a generalizar bem para dados nunca vistos.\n",
    "\n",
    "Estes gr√°ficos fornecem, portanto, uma ferramenta essencial de diagn√≥stico e s√£o altamente recomendados como parte integrante de qualquer processo de treino de redes neuronais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43mAwfAPQj3J"
   },
   "outputs": [],
   "source": [
    "# Plot training history with data from the callbacks\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1) # Adjusted to match the number of epochs\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o Final no Conjunto de Teste\n",
    "\n",
    "Ap√≥s o treino e valida√ß√£o do modelo, foi realizada a **avalia√ß√£o final no conjunto de teste**. Esta etapa √© essencial para medir a capacidade do modelo de generalizar para dados completamente novos, que n√£o foram utilizados nem durante o treino nem na valida√ß√£o.\n",
    "\n",
    "### M√©tricas Obtidas\n",
    "\n",
    "A avalia√ß√£o produz duas m√©tricas principais:\n",
    "\n",
    "- **Test Accuracy** (`test_acc`): Representa a percentagem de classifica√ß√µes corretas no conjunto de teste.\n",
    "- **Test Loss** (`test_loss`): Indica o valor da fun√ß√£o de perda nesse conjunto, permitindo compreender se o modelo ainda apresenta erros substanciais.\n",
    "\n",
    "Estes valores fornecem uma estimativa objetiva do desempenho real do modelo em produ√ß√£o.\n",
    "\n",
    "### Visualiza√ß√£o de Previs√µes\n",
    "\n",
    "Para uma an√°lise qualitativa, foi implementada uma visualiza√ß√£o de **24 imagens aleat√≥rias do conjunto de teste** juntamente com as suas **previs√µes**. Esta abordagem tem os seguintes objetivos:\n",
    "\n",
    "- Observar se o modelo √© capaz de generalizar para imagens reais com varia√ß√µes visuais e de ilumina√ß√£o;\n",
    "- Identificar **casos corretos** e **erros de classifica√ß√£o**;\n",
    "- Avaliar a coer√™ncia visual das previs√µes em rela√ß√£o √† classe verdadeira.\n",
    "\n",
    "#### Detalhes da Visualiza√ß√£o:\n",
    "\n",
    "- Para cada imagem, s√£o apresentados:\n",
    "  - **True**: A classe real;\n",
    "  - **Pred**: A classe predita pelo modelo.\n",
    "- O t√≠tulo de cada imagem √© colorido:\n",
    "  - **Verde**: Previs√£o correta;\n",
    "  - **Vermelho**: Previs√£o incorreta.\n",
    "- As previs√µes s√£o obtidas atrav√©s do m√©todo `model.predict`, e a classe final √© extra√≠da com `argmax`.\n",
    "\n",
    "### Import√¢ncia da An√°lise Qualitativa\n",
    "\n",
    "Apesar das m√©tricas globais fornecerem uma vis√£o estat√≠stica do desempenho, esta an√°lise visual permite:\n",
    "\n",
    "- Entender **quais tipos de objetos s√£o mais dif√≠ceis de classificar**;\n",
    "- Verificar **padr√µes de erro recorrentes**, como confus√£o entre vidro e pl√°stico ou entre papel e cart√£o;\n",
    "- Apoiar a decis√£o sobre poss√≠veis melhorias no modelo ou na prepara√ß√£o dos dados.\n",
    "\n",
    "Este tipo de visualiza√ß√£o √©, portanto, fundamental para interpretar os resultados do modelo no contexto da aplica√ß√£o real ‚Äî neste caso, uma app de reconhecimento autom√°tico de res√≠duos atrav√©s da c√¢mara do dispositivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Visualize some predictions\n",
    "import numpy as np\n",
    "\n",
    "# Get class names from your dataset\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Function to show predictions for a batch of images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    for i in range(24):\n",
    "        plt.subplot(6, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        correct = labels[i] == pred_classes[i]\n",
    "        color = \"green\" if correct else \"red\"\n",
    "        \n",
    "        plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[pred_classes[i]]}\", \n",
    "                 color=color)\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
