{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bef89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho local para a pasta raiz do projeto\n",
    "root_path = \"./\"  \n",
    "\n",
    "# Listar diretorias no caminho raiz\n",
    "print(\"Diretorias no caminho raiz:\")\n",
    "print(os.listdir(root_path))\n",
    "\n",
    "# Verificar conte√∫do de um caminho espec√≠fico\n",
    "specific_path = os.path.join(root_path, \"garbage-noaug-70-15-15\")\n",
    "if os.path.exists(specific_path):\n",
    "    print(f\"\\n Conte√∫do de {specific_path}:\")\n",
    "    print(os.listdir(specific_path))\n",
    "else:\n",
    "    print(f\"\\n Caminho {specific_path} n√£o existe\")\n",
    "\n",
    "# Fun√ß√£o para listar diretorias com profundidade\n",
    "def list_dirs(path, indent=0):\n",
    "    for item in os.listdir(path):\n",
    "        full_path = os.path.join(path, item)\n",
    "        if os.path.isdir(full_path):\n",
    "            print(\" \" * indent + \"üìÅ \" + item)\n",
    "            if indent < 4:\n",
    "                list_dirs(full_path, indent + 2)\n",
    "        else:\n",
    "            print(\" \" * indent + \"üìÑ \" + item)\n",
    "\n",
    "# Explorar estrutura de diretorias\n",
    "print(\"\\n Estrutura de diretorias:\")\n",
    "list_dirs(root_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Metal GPU detection for Apple Silicon\n",
    "try:\n",
    "    # First try looking for GPU devices (newer TF versions label Metal as GPU)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if len(gpus) > 0:\n",
    "        print(f\"Found {len(gpus)} GPU device(s)\")\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU acceleration enabled (Metal)\")\n",
    "    # If no GPU found, try looking specifically for MPS devices\n",
    "    elif hasattr(tf.config, 'list_physical_devices') and len(tf.config.list_physical_devices('MPS')) > 0:\n",
    "        mps_devices = tf.config.list_physical_devices('MPS')\n",
    "        tf.config.experimental.set_visible_devices(mps_devices[0], 'MPS')\n",
    "        print(\"MPS (Metal) device enabled\")\n",
    "    else:\n",
    "        print(\"No GPU or MPS device found, using CPU\")\n",
    "        \n",
    "    # Verify what device is being used\n",
    "    print(\"\\nDevice being used:\", tf.config.get_visible_devices())\n",
    "    \n",
    "    # Test with a simple operation to confirm GPU usage\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"Matrix multiplication result:\", c)\n",
    "        print(\"GPU test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up GPU: {e}\")\n",
    "    print(\"Falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2edb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision (faster on GPU)\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')  # Use FP16 instead of FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8914c842",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Carregamento e Prepara√ß√£o dos Dados com Aumento Seletivo de Classes Minorit√°rias\n",
    "\n",
    "Este bloco de c√≥digo trata da prepara√ß√£o e carregamento dos dados, com foco na aplica√ß√£o de **data augmentation condicional** √†s **classes minorit√°rias**. Al√©m disso, √© realizado o c√°lculo de **pesos de classe** e aplicadas otimiza√ß√µes de desempenho com *shuffle* e *prefetching*. Esta estrat√©gia visa melhorar a capacidade do modelo de aprender padr√µes visuais em classes sub-representadas, promovendo um treino mais equilibrado.\n",
    "\n",
    "#### Defini√ß√£o de Caminhos\n",
    "\n",
    "```python\n",
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "```\n",
    "\n",
    "Define as diretorias onde se encontram as imagens organizadas por classe. O caminho `specific_path` representa a localiza√ß√£o base do dataset, e os subdiretorias `train`, `valid` e `test` cont√™m os dados de treino, valida√ß√£o e teste, respetivamente.\n",
    "\n",
    "#### Configura√ß√µes de Imagem\n",
    "\n",
    "```python\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "```\n",
    "\n",
    "- `IMG_SIZE`: Redimensiona todas as imagens para 128x128, o que permite acelerar o treino e reduzir o consumo de mem√≥ria;\n",
    "- `BATCH_SIZE`: Um valor de 16 promove estabilidade de treino e compatibilidade com m√°quinas com mem√≥ria limitada.\n",
    "\n",
    "#### Carregamento do Dataset e C√°lculo de Pesos\n",
    "\n",
    "```python\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "```\n",
    "\n",
    "Carrega as imagens a partir das subpastas e associa automaticamente cada imagem ao respetivo r√≥tulo.\n",
    "\n",
    "Para equilibrar o impacto das classes com menor frequ√™ncia, s√£o calculados **pesos de classe** com:\n",
    "\n",
    "```python\n",
    "train_labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0)\n",
    "class_weights = class_weight.compute_class_weight(...)\n",
    "```\n",
    "\n",
    "Estes pesos s√£o posteriormente utilizados durante o treino para penalizar mais os erros em classes menos representadas.\n",
    "\n",
    "#### Estrat√©gia de Data Augmentation para Classes Minorit√°rias\n",
    "\n",
    "Ao inv√©s de aplicar *data augmentation* uniformemente, foi implementado um mecanismo **condicional** que afeta apenas as classes minorit√°rias:\n",
    "\n",
    "```python\n",
    "minority_classes = [0, 1, 5, 9]  # battery, biological, metal, trash\n",
    "```\n",
    "\n",
    "Foi definida uma fun√ß√£o de aumento com v√°rias transforma√ß√µes:\n",
    "\n",
    "```python\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.image.random_hue(image, 0.05)\n",
    "    return image, label\n",
    "```\n",
    "\n",
    "Esta fun√ß√£o √© aplicada **apenas se o r√≥tulo da imagem pertencer a uma classe minorit√°ria**, com:\n",
    "\n",
    "```python\n",
    "train_dataset_aug = train_dataset.map(augment_conditionally, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "```\n",
    "\n",
    "Este m√©todo permite aumentar a variabilidade visual das classes menos representadas, ajudando o modelo a generalizar melhor para essas categorias e evitando *overfitting* em classes com mais exemplos.\n",
    "\n",
    "#### Carregamento de Valida√ß√£o e Teste\n",
    "\n",
    "```python\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "```\n",
    "\n",
    "Os conjuntos de valida√ß√£o e teste s√£o carregados sem altera√ß√µes e usados para monitoriza√ß√£o cont√≠nua e avalia√ß√£o final.\n",
    "\n",
    "#### Otimiza√ß√£o do Pipeline\n",
    "\n",
    "Posteriormente, pode aplicar-se *shuffle* e *prefetching* ao `train_dataset_aug`, `val_dataset` e `test_dataset` para melhorar o desempenho e a aleatoriedade durante o treino.\n",
    "\n",
    "Esta abordagem avan√ßada e seletiva de data augmentation combinada com repondera√ß√£o por classe contribui para melhorar a equidade e robustez do modelo, sendo particularmente √∫til em datasets naturalmente desbalanceados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82791984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# 1. Carregar dataset com augmentation\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Extrair r√≥tulos dos batches do dataset\n",
    "train_labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0)\n",
    "\n",
    "# Calcular os pesos das classes\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Aumentar o dataset de treinamento com t√©cnicas de data augmentation (das classes minorit√°rias)\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.image.random_hue(image, 0.05)\n",
    "    return image, label\n",
    "\n",
    "# Definir classes minorit√°rias\n",
    "minority_classes = [0, 1, 5, 9]  # battery, biological, metal, trash\n",
    "\n",
    "def augment_conditionally(image, label):\n",
    "    return tf.cond(\n",
    "        tf.reduce_any([tf.equal(label, tf.constant(c)) for c in minority_classes]),\n",
    "        lambda: augment_image(image, label),\n",
    "        lambda: (image, label)\n",
    "    )\n",
    "\n",
    "train_dataset_aug = train_dataset.map(augment_conditionally, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f97c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset_aug = train_dataset_aug.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 2. Feature Extraction ‚Äì VGG16 congelada\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False  # congelado inicialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# Extrator de features (VGG16 congelada)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Camadas densas otimizadas\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# Sa√≠da\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# Modelo final\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compila√ß√£o\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumo\n",
    "model.summary()\n",
    "\n",
    "# EarlyStopping mais agressivo\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Treino com feature extraction\n",
    "history = model.fit(\n",
    "    train_dataset_aug,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 5. Fine-tuning ‚Äì descongela √∫ltimas camadas\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Novo EarlyStopping para fine-tuning\n",
    "early_stopping_ft = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Opcional: ajuste din√¢mico da LR\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "\n",
    "# Treino com fine-tuning\n",
    "model.fit(\n",
    "    train_dataset_aug,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping_ft, reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.save_weights('models/vgg16.weights.h5')\n",
    "# Salvar o modelo completo\n",
    "model.save('models/vgg16_finetuned_model.keras')\n",
    "print(\"Modelo salvo como 'vgg16_finetuned_model.keras' e pesos como 'vgg16_finetuned_weights.h5'.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc750a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Avalia√ß√£o\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# 8. Previs√µes para m√©tricas\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# 9. Relat√≥rio e Confusion Matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ce264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected plotting code for newer TensorFlow versions\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Use the already defined class_names variable\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Function to show predictions for a batch of images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    num_images = images.shape[0]\n",
    "    grid_rows = int(np.ceil(num_images / 4))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_rows, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        correct = labels[i] == pred_classes[i]\n",
    "        color = \"green\" if correct else \"red\"\n",
    "        \n",
    "        plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[pred_classes[i]]}\", \n",
    "                 color=color)\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
