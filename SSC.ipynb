{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9rCT0KQzLV4Y"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image_dataset_from_directory\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "from keras.utils import image_dataset_from_directory\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gnERLOeGV_O",
        "outputId": "e457719c-f736-40cf-c5cb-100833cb2b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directories in Drive root:\n",
            "['Colab Notebooks']\n",
            "\n",
            "Contents of /content/drive/MyDrive/Colab Notebooks/garbage-70-15-15:\n",
            "['test', 'train', 'valid', 'README.roboflow.txt', 'README.dataset.txt']\n",
            "\n",
            "Directory structure:\n",
            "📁 Colab Notebooks\n",
            "  📄 SSC.ipynb\n",
            "  📁 garbage-dataset\n",
            "    📄 .DS_Store\n",
            "    📁 biological\n",
            "    📁 paper\n",
            "    📁 metal\n",
            "    📁 trash\n",
            "    📁 glass\n",
            "    📁 clothes\n",
            "    📁 cardboard\n",
            "    📁 battery\n",
            "    📁 shoes\n",
            "    📁 plastic\n",
            "  📁 garbage-70-15-15\n",
            "    📁 test\n",
            "    📁 train\n",
            "    📁 valid\n",
            "    📄 README.roboflow.txt\n",
            "    📄 README.dataset.txt\n",
            "  📁 garbage-noaug-70-15-15\n",
            "    📄 .DS_Store\n",
            "    📁 valid\n",
            "    📁 test\n",
            "    📁 train\n",
            "    📄 README.roboflow.txt\n",
            "    📄 README.dataset.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Caminho local para a pasta raiz do projeto\n",
        "root_path = \"./\"  # ou o caminho absoluto, ex: \"C:/Users/teu_usuario/Documents/SSC-AI-GARBAGE-DETECTION\"\n",
        "\n",
        "# Listar diretórios no caminho raiz\n",
        "print(\"📁 Diretórios no caminho raiz:\")\n",
        "print(os.listdir(root_path))\n",
        "\n",
        "# Verificar conteúdo de um caminho específico\n",
        "specific_path = os.path.join(root_path, \"garbage-noaug-70-15-15\")\n",
        "if os.path.exists(specific_path):\n",
        "    print(f\"\\n📁 Conteúdo de {specific_path}:\")\n",
        "    print(os.listdir(specific_path))\n",
        "else:\n",
        "    print(f\"\\n❌ Caminho {specific_path} não existe\")\n",
        "\n",
        "# Função para listar diretórios com profundidade\n",
        "def list_dirs(path, indent=0):\n",
        "    for item in os.listdir(path):\n",
        "        full_path = os.path.join(path, item)\n",
        "        if os.path.isdir(full_path):\n",
        "            print(\" \" * indent + \"📁 \" + item)\n",
        "            if indent < 4:\n",
        "                list_dirs(full_path, indent + 2)\n",
        "        else:\n",
        "            print(\" \" * indent + \"📄 \" + item)\n",
        "\n",
        "# Explorar estrutura de diretórios\n",
        "print(\"\\n📂 Estrutura de diretórios:\")\n",
        "list_dirs(root_path, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM_Q87BIO7Bo",
        "outputId": "8bf53a53-57b1-45bd-d7ac-7e0b0aa95b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 41648 files belonging to 10 classes.\n",
            "Found 2995 files belonging to 10 classes.\n",
            "Found 2995 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = specific_path + \"/train\"\n",
        "validation_dir = specific_path + \"/valid\"\n",
        "test_dir = specific_path + \"/test\"\n",
        "\n",
        "# Images are 640, but 224 is way faster for training\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYyaeQfoQP3B",
        "outputId": "cca51f1e-b6b2-4db3-8ccd-dabaf62b3556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data batch shape: (32, 224, 224, 3)\n",
            "labels batch shape: (32,)\n"
          ]
        }
      ],
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CqMUaOEQawK"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "# Dropout for better generalization\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
        "    metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WURl_OhwQg_E",
        "outputId": "3484b4a3-12a5-439a-cf55-da9bd59f90ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m   2/1302\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:16\u001b[0m 4s/step - accuracy: 0.2344 - loss: 2.2434 "
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43mAwfAPQj3J"
      },
      "outputs": [],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo' , label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
