{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6f102",
   "metadata": {},
   "source": [
    "### Configura√ß√£o da GPU no TensorFlow\n",
    "\n",
    "Antes de iniciar o treino do modelo, √© importante garantir que o *TensorFlow* est√° configurado para utilizar a GPU (caso esteja dispon√≠vel). Al√©m disso, ativamos o *memory growth*, que permite ao *TensorFlow* alocar mem√≥ria da GPU conforme necess√°rio, evitando reservar toda a mem√≥ria de uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bef89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar dispositivos f√≠sicos do tipo 'GPU' dispon√≠veis\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Se houver GPUs dispon√≠veis, configurar o memory growth\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Ativar crescimento din√¢mico da mem√≥ria da GPU\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        # Caso a GPU j√° tenha sido inicializada, n√£o √© poss√≠vel alterar a configura√ß√£o\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10cb5f",
   "metadata": {},
   "source": [
    "### Explora√ß√£o da Estrutura de Diretorias\n",
    "\n",
    "Antes de carregar os dados, √© importante garantir que o caminho para os ficheiros est√° correto e que a estrutura de diretorias est√° bem organizada. O seguinte bloco de c√≥digo permite:\n",
    "\n",
    "- Definir o caminho base (`root_path`) para o projeto.\n",
    "- Listar as diretorias existentes na raiz.\n",
    "- Verificar se o diret√≥rio do dataset (`garbage-noaug-70-15-15`) existe e visualizar o seu conte√∫do.\n",
    "- Explorar de forma recursiva a estrutura de diretorias, mostrando ficheiros e pastas com indenta√ß√£o hier√°rquica.\n",
    "\n",
    "Este passo √© essencial para:\n",
    "- Validar que os dados est√£o organizados corretamente.\n",
    "- Evitar erros de caminho ao carregar imagens para treino, valida√ß√£o e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Caminho local para a pasta raiz do projeto\n",
    "root_path = \"./\"  \n",
    "\n",
    "# Listar diretorias no caminho raiz\n",
    "print(\"Diretorias no caminho raiz:\")\n",
    "print(os.listdir(root_path))\n",
    "\n",
    "# Verificar conte√∫do de um caminho espec√≠fico\n",
    "specific_path = os.path.join(root_path, \"garbage-noaug-70-15-15\")\n",
    "if os.path.exists(specific_path):\n",
    "    print(f\"\\nConte√∫do de {specific_path}:\")\n",
    "    print(os.listdir(specific_path))\n",
    "else:\n",
    "    print(f\"\\nCaminho {specific_path} n√£o existe\")\n",
    "\n",
    "# Fun√ß√£o para listar diretorias com profundidade\n",
    "def list_dirs(path, indent=0):\n",
    "    for item in os.listdir(path):\n",
    "        full_path = os.path.join(path, item)\n",
    "        if os.path.isdir(full_path):\n",
    "            print(\" \" * indent + \"üìÅ \" + item)\n",
    "            if indent < 4:\n",
    "                list_dirs(full_path, indent + 2)\n",
    "        else:\n",
    "            print(\" \" * indent + \"üìÑ \" + item)\n",
    "\n",
    "# Explorar estrutura de diretorias\n",
    "print(\"\\nEstrutura de diretorias:\")\n",
    "list_dirs(root_path, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc30a37",
   "metadata": {},
   "source": [
    "### Dete√ß√£o e Configura√ß√£o Otimizada de GPU (Apple Silicon / Metal)\n",
    "\n",
    "Este bloco de c√≥digo trata da dete√ß√£o e configura√ß√£o de dispositivos de acelera√ß√£o como GPUs ou MPS (*Metal Performance Shaders*), especialmente √∫til em Macs com Apple Silicon.\n",
    "\n",
    "#### Funcionalidades:\n",
    "- Procura dispositivos GPU dispon√≠veis (*TensorFlow* ‚â• 2.5 reconhece *Metal* como `GPU`).\n",
    "- Se n√£o encontrar GPU, tenta encontrar dispositivos `MPS` diretamente.\n",
    "- Ativa `memory growth` para evitar aloca√ß√£o antecipada excessiva de mem√≥ria.\n",
    "- Verifica e imprime os dispositivos vis√≠veis.\n",
    "- Executa uma multiplica√ß√£o de matrizes simples para testar a acelera√ß√£o via GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Metal GPU detection for Apple Silicon\n",
    "try:\n",
    "    # First try looking for GPU devices (newer TF versions label Metal as GPU)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if len(gpus) > 0:\n",
    "        print(f\"Found {len(gpus)} GPU device(s)\")\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU acceleration enabled (Metal)\")\n",
    "    # If no GPU found, try looking specifically for MPS devices\n",
    "    elif hasattr(tf.config, 'list_physical_devices') and len(tf.config.list_physical_devices('MPS')) > 0:\n",
    "        mps_devices = tf.config.list_physical_devices('MPS')\n",
    "        tf.config.experimental.set_visible_devices(mps_devices[0], 'MPS')\n",
    "        print(\"MPS (Metal) device enabled\")\n",
    "    else:\n",
    "        print(\"No GPU or MPS device found, using CPU\")\n",
    "        \n",
    "    # Verify what device is being used\n",
    "    print(\"\\nDevice being used:\", tf.config.get_visible_devices())\n",
    "    \n",
    "    # Test with a simple operation to confirm GPU usage\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"Matrix multiplication result:\", c)\n",
    "        print(\"GPU test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up GPU: {e}\")\n",
    "    print(\"Falling back to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bba3e2",
   "metadata": {},
   "source": [
    "### Mixed Precision Training (FP16)\n",
    "\n",
    "Este bloco de c√≥digo ativa o **mixed precision training**, que usa `float16` (FP16) em vez de `float32` (FP32), sempre que poss√≠vel.\n",
    "\n",
    "#### Benef√≠cios:\n",
    "- Maior desempenho em GPUs modernas, como as da arquitetura *Volta, Turing, Ampere* ou *Apple Silicon* com suporte a *Metal*.\n",
    "- Menor uso de mem√≥ria, permitindo treinar modelos maiores ou\n",
    "\n",
    "#### Como funciona:\n",
    "- Opera√ß√µes matem√°ticas intensas usam `float16`\n",
    "- A perda (`loss`) e os pesos principais mant√™m-se em `float32` para estabilidade num√©rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2edb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision (faster on GPU)\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')  # Use FP16 instead of FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe6d04",
   "metadata": {},
   "source": [
    "\n",
    "### Carregamento e Prepara√ß√£o dos Dados com Pesos de Classe\n",
    "\n",
    "Este bloco de c√≥digo trata da prepara√ß√£o e carregamento dos dados para treino do modelo, incluindo o c√°lculo de **pesos de classe** para compensar desequil√≠brios no *dataset*, bem como otimiza√ß√µes com *prefetching* e *shuffling*. Esta prepara√ß√£o √© fundamental para o treino eficaz de modelos baseados em transfer√™ncia de aprendizagem, como a VGG16.\n",
    "\n",
    "#### Defini√ß√£o de Caminhos\n",
    "\n",
    "```python\n",
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "```\n",
    "\n",
    "Define os diret√≥rios onde se encontram as imagens organizadas por classe. O caminho `specific_path` representa a localiza√ß√£o base do *dataset*, e os subdiret√≥rios `train`, `valid` e `test` cont√™m os dados de treino, valida√ß√£o e teste, respetivamente.\n",
    "\n",
    "#### Configura√ß√µes de Imagem\n",
    "\n",
    "```python\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "```\n",
    "\n",
    "- `IMG_SIZE`: Redimensiona todas as imagens para 128x128, o que permite acelerar o treino e reduzir o consumo de mem√≥ria, mantendo um n√≠vel de detalhe suficiente.\n",
    "- `BATCH_SIZE`: Um valor mais pequeno (16) √© adotado para permitir um treino mais est√°vel e compat√≠vel com hardware com menos mem√≥ria.\n",
    "\n",
    "#### Carregamento do Dataset e C√°lculo de Pesos\n",
    "\n",
    "```python\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "```\n",
    "\n",
    "Carrega automaticamente as imagens a partir das subpastas e associa cada imagem ao respetivo r√≥tulo com base no nome da diretoria.\n",
    "\n",
    "Em seguida, os r√≥tulos s√£o extra√≠dos do *dataset* com:\n",
    "\n",
    "```python\n",
    "train_labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0)\n",
    "```\n",
    "\n",
    "e os **pesos de classe** s√£o calculados com:\n",
    "\n",
    "```python\n",
    "class_weights = class_weight.compute_class_weight(...)\n",
    "```\n",
    "\n",
    "Esta abordagem √© essencial quando o *dataset* apresenta **desequil√≠brio entre classes**, permitindo que o modelo atribua maior import√¢ncia √†s classes menos representadas durante o processo de treino. O dicion√°rio `class_weights` √© posteriormente utilizado no m√©todo `model.fit()`.\n",
    "\n",
    "#### Carregamento de Valida√ß√£o e Teste\n",
    "\n",
    "```python\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(...)\n",
    "```\n",
    "\n",
    "Os conjuntos de valida√ß√£o e teste s√£o carregados de forma semelhante, mas sem necessidade de c√°lculo de pesos. Estes conjuntos s√£o usados para monitorizar o desempenho do modelo ao longo do treino e na fase de avalia√ß√£o final, respetivamente.\n",
    "\n",
    "#### Otimiza√ß√£o com *Shuffle* e *Prefetching*\n",
    "\n",
    "```python\n",
    ".shuffle(buffer_size=10).prefetch(buffer_size=AUTO_TUNE)\n",
    "```\n",
    "\n",
    "Aplica duas otimiza√ß√µes fundamentais:\n",
    "\n",
    "- **Shuffle**: embaralha os dados, ajudando a evitar que o modelo aprenda padr√µes indesejados na ordem dos dados;\n",
    "- **Prefetch**: carrega batches futuros em paralelo com o treino, reduzindo a lat√™ncia entre itera√ß√µes e melhorando a efici√™ncia geral do *pipeline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82791984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o das diretorias de treino, valida√ß√£o e teste\n",
    "train_dir = specific_path + \"/train\"\n",
    "validation_dir = specific_path + \"/valid\"\n",
    "test_dir = specific_path + \"/test\"\n",
    "\n",
    "# Definir o tamanho das imagens e o tamanho do batch\n",
    "# (Imagens originais t√™m 640px, mas 128px acelera o treino)\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE), # Redimensionar imagens\n",
    "    batch_size=BATCH_SIZE            # Dividir em batches\n",
    ")\n",
    "\n",
    "# Extrair r√≥tulos dos batches do dataset\n",
    "train_labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0)\n",
    "\n",
    "# Calcular os pesos das classes\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Carregar o dataset de valida√ß√£o\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Carregar o dataset de teste\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Aplicar preprocessamento de imagens\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=10).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef6c52",
   "metadata": {},
   "source": [
    "### Prepara√ß√£o do Modelo com Transfer√™ncia de Aprendizagem\n",
    "\n",
    "```python\n",
    "base_model = tf.keras.applications.VGG16(...)\n",
    "base_model.trainable = False\n",
    "```\n",
    "\n",
    "O modelo base escolhido √© a **VGG16**, pr√©-treinada no *dataset ImageNet*. Ao definir `trainable = False`, congela-se a base convolucional, utilizando-a apenas como **extrator de caracter√≠sticas** (*feature extractor*) nesta primeira fase. Camadas densas personalizadas ser√£o adicionadas no topo para adaptar o modelo √† tarefa espec√≠fica de classifica√ß√£o de res√≠duos.\n",
    "\n",
    "Esta abordagem reduz o tempo de treino, evita sobreajuste em datasets pequenos e tira partido do conhecimento previamente aprendido em tarefas visuais gen√©ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd112f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction ‚Äì VGG16 congelada\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False  # congelado inicialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968ea39",
   "metadata": {},
   "source": [
    "\n",
    "### Constru√ß√£o e Compila√ß√£o do Modelo com Transfer√™ncia de Aprendizagem (VGG16)\n",
    "\n",
    "Este bloco de c√≥digo define a arquitetura completa do modelo com base em **transfer√™ncia de aprendizagem**, combinando uma rede convolucional pr√©-treinada (neste caso, VGG16) com camadas densas personalizadas. A base convolucional √© utilizada como **extrator de caracter√≠sticas**, e permanece congelada na fase inicial de treino.\n",
    "\n",
    "#### Defini√ß√£o da Entrada e Pr√©-processamento\n",
    "\n",
    "```python\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "```\n",
    "\n",
    "- Define a forma de entrada das imagens (RGB);\n",
    "- Aplica normaliza√ß√£o dos valores de pixel para o intervalo [0, 1], o que melhora a estabilidade do treino.\n",
    "\n",
    "#### Extrator de Caracter√≠sticas (Base Pr√©-treinada)\n",
    "\n",
    "- A `base_model` (como VGG16) √© utilizada com os seus pesos pr√©-treinados no *ImageNet*;\n",
    "- √â aplicada com `training=False` para manter os seus pesos congelados;\n",
    "- A camada `GlobalAveragePooling2D` reduz a dimensionalidade, convertendo os mapas de ativa√ß√£o em vetores.\n",
    "\n",
    "#### Camadas Densas Personalizadas\n",
    "\n",
    "As camadas densas adicionadas ao topo da rede extraem rela√ß√µes mais complexas entre as caracter√≠sticas aprendidas:\n",
    "\n",
    "- `Dropout`: T√©cnica de regulariza√ß√£o para reduzir *overfitting*;\n",
    "- `Dense`: Camadas totalmente ligadas com 512 e 256 unidades;\n",
    "- `BatchNormalization`: Normaliza as ativa√ß√µes entre batches, estabilizando o treino;\n",
    "- `ReLU`: Fun√ß√£o de ativa√ß√£o n√£o-linear comum em redes profundas.\n",
    "\n",
    "#### Camada de Sa√≠da\n",
    "\n",
    "- Camada final com tantos neur√≥nios quanto o n√∫mero de classes;\n",
    "- A fun√ß√£o `softmax` converte os logits em probabilidades para cada classe.\n",
    "\n",
    "#### Cria√ß√£o e Compila√ß√£o do Modelo\n",
    "\n",
    "- O modelo √© instanciado usando a API funcional do Keras;\n",
    "- O otimizador `Adam` √© utilizado com uma taxa de aprendizagem de `0.0003`;\n",
    "- A fun√ß√£o de perda `sparse_categorical_crossentropy` √© usada para *targets* inteiros;\n",
    "- A m√©trica principal √© `accuracy`.\n",
    "\n",
    "#### Sum√°rio do Modelo\n",
    "\n",
    "Apresenta um resumo da arquitetura do modelo, incluindo o n√∫mero de par√¢metros trein√°veis e n√£o trein√°veis, bem como a estrutura das camadas.\n",
    "\n",
    "Esta combina√ß√£o de transfer√™ncia de aprendizagem com uma cabe√ßa densa personalizada permite aproveitar o poder dos modelos de larga escala, adaptando-os eficazmente √† tarefa espec√≠fica de classifica√ß√£o de res√≠duos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# Extrator de features (VGG16 congelada)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Camadas densas otimizadas\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# Sa√≠da\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# Modelo final\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compila√ß√£o\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e04947",
   "metadata": {},
   "source": [
    "\n",
    "### Treino com Transfer√™ncia de Aprendizagem e *Fine-Tuning*\n",
    "\n",
    "Este bloco de c√≥digo descreve as duas fases principais de treino do modelo baseado em **transfer√™ncia de aprendizagem com VGG16**, incluindo **feature extraction** inicial e subsequente **fine-tuning** das camadas superiores da rede. S√£o tamb√©m aplicadas t√©cnicas de *early stopping* e ajuste din√¢mico da *learning rate* para melhorar a efici√™ncia e estabilidade do treino.\n",
    "\n",
    "#### EarlyStopping Inicial\n",
    "\n",
    "- Monitoriza a m√©trica de `val_loss`;\n",
    "- Interrompe o treino se a perda de valida√ß√£o n√£o melhorar durante 5 √©pocas consecutivas;\n",
    "- Restaura os pesos da √©poca com melhor desempenho.\n",
    "\n",
    "#### Fase 1 ‚Äì Feature Extraction\n",
    "\n",
    "- O modelo √© treinado com a **VGG16 congelada**;\n",
    "- Apenas as camadas densas adicionadas no topo s√£o ajustadas;\n",
    "- Utiliza-se o dataset completo e monitoriza-se a valida√ß√£o durante o treino;\n",
    "- EarlyStopping assegura treino eficiente sem overfitting.\n",
    "\n",
    "#### Fase 2 ‚Äì *Fine-Tuning*\n",
    "\n",
    "- Descongela as **√∫ltimas 50 camadas** da VGG16 para permitir o ajuste fino dos pesos;\n",
    "- As camadas mais antigas permanecem congeladas, preservando o conhecimento gen√©rico aprendido no *ImageNet*.\n",
    "\n",
    "O modelo √© recompilado com uma taxa de aprendizagem reduzida:\n",
    "\n",
    "- A *learning rate* mais baixa evita altera√ß√µes bruscas nos pesos durante o *fine-tuning*.\n",
    "\n",
    "#### *Callbacks* para *Fine-Tuning*\n",
    "\n",
    "- Um novo `EarlyStopping` com os mesmos par√¢metros √© aplicado;\n",
    "- O callback `ReduceLROnPlateau` reduz dinamicamente a *learning rate* se a `val_loss` estagnar.\n",
    "\n",
    "#### Execu√ß√£o do *Fine-Tuning*\n",
    "\n",
    "- O treino √© realizado com os pesos de classe calculados previamente;\n",
    "- As melhorias obtidas nesta fase permitem uma melhor adapta√ß√£o do modelo √†s especificidades do dom√≠nio (res√≠duos urbanos).\n",
    "\n",
    "#### Salvamento do Modelo\n",
    "\n",
    "- Os **pesos do modelo** e o **modelo completo** (arquitetura + pesos + estado do otimizador) s√£o guardados para reutiliza√ß√£o futura;\n",
    "- Permite retomar o treino, realizar infer√™ncia ou exportar para produ√ß√£o.\n",
    "\n",
    "Este *pipeline* estruturado em duas fases permite combinar a robustez de um modelo pr√©-treinado com a capacidade de especializa√ß√£o para uma tarefa concreta, otimizando tanto o desempenho como o tempo de treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping mais agressivo\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 4. Treino com feature extraction\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 5. Fine-tuning ‚Äì descongela √∫ltimas camadas\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Novo EarlyStopping para fine-tuning\n",
    "early_stopping_ft = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Ajuste din√¢mico da LR\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "\n",
    "# Treino com fine-tuning\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping_ft, reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "model.save_weights('models/vgg16_noaug.weights.h5')\n",
    "# Salvar o modelo completo\n",
    "model.save('models/vgg16_noaug.keras')\n",
    "print(\"Modelo salvo como 'vgg16_noaug.keras' e pesos como 'vgg16_noaug.h5'.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054648e",
   "metadata": {},
   "source": [
    "\n",
    "### Avalia√ß√£o Final do Modelo e An√°lise de Desempenho\n",
    "\n",
    "Ap√≥s o treino e *fine-tuning* do modelo, realiza-se a **avalia√ß√£o final** no conjunto de teste. Esta etapa permite medir a capacidade do modelo para generalizar perante dados nunca vistos, e avaliar quantitativamente e qualitativamente os seus erros e acertos.\n",
    "\n",
    "#### Avalia√ß√£o no Conjunto de Teste\n",
    "\n",
    "- O m√©todo `evaluate` calcula a **loss** e **accuracy** do modelo sobre o conjunto de teste;\n",
    "- A `test accuracy` representa a percentagem de classifica√ß√µes corretas;\n",
    "- A `test loss` quantifica o erro m√©dio cometido pelo modelo.\n",
    "\n",
    "#### Previs√µes e Compara√ß√£o com Valores Reais\n",
    "\n",
    "- `y_pred`: Armazena as classes previstas pelo modelo (via `argmax`);\n",
    "- `y_true`: Cont√©m os r√≥tulos reais;\n",
    "- Esta informa√ß√£o √© essencial para gerar m√©tricas adicionais al√©m da *accuracy*.\n",
    "\n",
    "#### Relat√≥rio de Classifica√ß√£o\n",
    "\n",
    "Gera um relat√≥rio com as seguintes m√©tricas por classe:\n",
    "\n",
    "- **Precision**: propor√ß√£o de previs√µes corretas entre todas as previs√µes para uma classe;\n",
    "- **Recall**: propor√ß√£o de previs√µes corretas entre todos os exemplos reais dessa classe;\n",
    "- **F1-score**: m√©dia harm√≥nica entre precision e *recall*;\n",
    "- **Support**: n√∫mero de ocorr√™ncias reais da classe no conjunto de teste.\n",
    "\n",
    "Este relat√≥rio fornece uma vis√£o detalhada do desempenho do modelo em cada categoria de res√≠duos.\n",
    "\n",
    "#### Matriz de Confus√£o\n",
    "\n",
    "- A **matriz de confus√£o** permite visualizar os erros cometidos por classe;\n",
    "- Cada c√©lula `[i][j]` representa o n√∫mero de exemplos da classe `i` que foram classificados como `j`;\n",
    "- A diagonal principal representa acertos ‚Äî quanto mais dominante, melhor o desempenho;\n",
    "- Erros sistem√°ticos podem indicar confus√£o entre classes visualmente semelhantes (ex: metal vs pl√°stico).\n",
    "\n",
    "Esta an√°lise √© crucial para identificar padr√µes de erro, avaliar a robustez do modelo em cen√°rios reais e guiar melhorias futuras na arquitetura, dados ou estrat√©gias de treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc750a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia√ß√£o\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Previs√µes para m√©tricas\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Relat√≥rio e Confusion Matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19418f8",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o da Evolu√ß√£o do Treino\n",
    "\n",
    "Para uma an√°lise mais clara e interpret√°vel do comportamento do modelo durante o treino, foi gerado um gr√°fico de dupla visualiza√ß√£o com os dados recolhidos a partir do hist√≥rico (`history`) fornecido pelo m√©todo `model.fit()`.\n",
    "\n",
    "### Conte√∫do Visualizado\n",
    "\n",
    "O gr√°fico apresenta duas m√©tricas fundamentais, tanto para os dados de treino como de valida√ß√£o:\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - Mostra a propor√ß√£o de previs√µes corretas realizadas pelo modelo.\n",
    "   - Indicador direto da efic√°cia do modelo em classificar corretamente os exemplos.\n",
    "\n",
    "2. **Loss**:\n",
    "   - Representa o valor da fun√ß√£o de perda, indicando o qu√£o bem o modelo est√° a ajustar-se aos dados.\n",
    "   - Quanto menor o valor, melhor o desempenho do modelo (em teoria).\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Esta visualiza√ß√£o tem como objetivo:\n",
    "\n",
    "- Identificar sinais de **overfitting** (quando a *accuracy* de treino continua a aumentar mas a de valida√ß√£o estagna ou diminui);\n",
    "- Confirmar a **converg√™ncia** do modelo (quando tanto a *loss* como a *accuracy* estabilizam);\n",
    "- Ajudar a determinar o n√∫mero ideal de √©pocas (epochs) para treino.\n",
    "\n",
    "### Interpreta√ß√£o\n",
    "\n",
    "- Um **comportamento ideal** √© caracterizado por curvas de treino e valida√ß√£o que convergem e permanecem relativamente pr√≥ximas.\n",
    "- Se a `validation loss` come√ßar a aumentar enquanto a `training loss` diminui, pode indicar **overfitting**.\n",
    "- Um bom alinhamento entre `training accuracy` e `validation accuracy` sugere que o modelo est√° a generalizar bem para dados nunca vistos.\n",
    "\n",
    "Estes gr√°ficos fornecem, portanto, uma ferramenta essencial de diagn√≥stico e s√£o altamente recomendados como parte integrante de qualquer processo de treino de redes neuronais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ce264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected plotting code for newer TensorFlow versions\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b0777",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o Final no Conjunto de Teste\n",
    "\n",
    "Ap√≥s o treino e valida√ß√£o do modelo, foi realizada a **avalia√ß√£o final no conjunto de teste**. Esta etapa √© essencial para medir a capacidade do modelo de generalizar para dados completamente novos, que n√£o foram utilizados nem durante o treino nem na valida√ß√£o.\n",
    "\n",
    "### M√©tricas Obtidas\n",
    "\n",
    "A avalia√ß√£o produz duas m√©tricas principais:\n",
    "\n",
    "- **Test Accuracy** (`test_acc`): Representa a percentagem de classifica√ß√µes corretas no conjunto de teste.\n",
    "- **Test Loss** (`test_loss`): Indica o valor da fun√ß√£o de perda nesse conjunto, permitindo compreender se o modelo ainda apresenta erros substanciais.\n",
    "\n",
    "Estes valores fornecem uma estimativa objetiva do desempenho real do modelo em produ√ß√£o.\n",
    "\n",
    "### Visualiza√ß√£o de Previs√µes\n",
    "\n",
    "Para uma an√°lise qualitativa, foi implementada uma visualiza√ß√£o de **24 imagens aleat√≥rias do conjunto de teste** juntamente com as suas **previs√µes**. Esta abordagem tem os seguintes objetivos:\n",
    "\n",
    "- Observar se o modelo √© capaz de generalizar para imagens reais com varia√ß√µes visuais e de ilumina√ß√£o;\n",
    "- Identificar **casos corretos** e **erros de classifica√ß√£o**;\n",
    "- Avaliar a coer√™ncia visual das previs√µes em rela√ß√£o √† classe verdadeira.\n",
    "\n",
    "#### Detalhes da Visualiza√ß√£o:\n",
    "\n",
    "- Para cada imagem, s√£o apresentados:\n",
    "  - **True**: A classe real;\n",
    "  - **Pred**: A classe predita pelo modelo.\n",
    "- O t√≠tulo de cada imagem √© colorido:\n",
    "  - **Verde**: Previs√£o correta;\n",
    "  - **Vermelho**: Previs√£o incorreta.\n",
    "- As previs√µes s√£o obtidas atrav√©s do m√©todo `model.predict`, e a classe final √© extra√≠da com `argmax`.\n",
    "\n",
    "### Import√¢ncia da An√°lise Qualitativa\n",
    "\n",
    "Apesar das m√©tricas globais fornecerem uma vis√£o estat√≠stica do desempenho, esta an√°lise visual permite:\n",
    "\n",
    "- Entender **quais tipos de objetos s√£o mais dif√≠ceis de classificar**;\n",
    "- Verificar **padr√µes de erro recorrentes**, como confus√£o entre vidro e pl√°stico ou entre papel e cart√£o;\n",
    "- Apoiar a decis√£o sobre poss√≠veis melhorias no modelo ou na prepara√ß√£o dos dados.\n",
    "\n",
    "Este tipo de visualiza√ß√£o √©, portanto, fundamental para interpretar os resultados do modelo no contexto da aplica√ß√£o real ‚Äî neste caso, uma app de reconhecimento autom√°tico de res√≠duos atrav√©s da c√¢mara do dispositivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Use the already defined class_names variable\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Function to show predictions for a batch of images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    num_images = images.shape[0]\n",
    "    grid_rows = int(np.ceil(num_images / 4))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(grid_rows, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        correct = labels[i] == pred_classes[i]\n",
    "        color = \"green\" if correct else \"red\"\n",
    "        \n",
    "        plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[pred_classes[i]]}\", \n",
    "                 color=color)\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
